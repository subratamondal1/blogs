{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6aaa9db-bf47-4bb0-9b7d-2b5bb4ed827d",
   "metadata": {},
   "source": [
    "# STATISTICS\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1681a993-9513-4921-b747-66145f63ddd8",
   "metadata": {},
   "source": [
    "## NORMAL / GAUSSIAN DISTRIBUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911aec6c-f1ad-4f3c-b128-debf36ea9767",
   "metadata": {},
   "source": [
    "Normal distribution is a type of probability distribution that describes how data are distributed around the mean. It has some properties that make it useful for analyzing data and making predictions.\n",
    "\n",
    "- Normal distribution is **symmetric** and bell-shaped, meaning that the left and right halves of the curve are mirror images of each other, and the curve is highest at the mean (center) and decreases gradually as it moves away from the center.\n",
    "\n",
    "- Normal distribution can be described by two parameters: the **mean** and the **standard deviation**. The mean is the average value of the data, and the standard deviation is a measure of how much the data vary from the mean. The standard deviation affects the shape of the curve: a smaller standard deviation makes the curve narrower and taller, and a larger standard deviation makes the curve wider and flatter.\n",
    "\n",
    "- Normal distribution follows some rules that can help us calculate probabilities and make inferences about the data. One of these rules is called the **empirical rule**, or the **68-95-99.7** rule. It states that in a normal distribution, about 68% of the data are within one standard deviation from the mean, about 95% of the data are within two standard deviations from the mean, and about 99.7% of the data are within three standard deviations from the mean. Another rule is called the **central limit theorem**. It states that if we take many random samples from any population, regardless of its shape, and calculate their means, then these sample means will follow a normal distribution with a mean equal to the population mean and a standard deviation equal to the population standard deviation divided by the square root of the sample size.\n",
    "\n",
    "- Normal distribution is widely used in many fields, such as natural sciences, social sciences, engineering, medicine, etc. It can help us model phenomena that are influenced by many random factors, such as height, weight, IQ, blood pressure, test scores, etc. It can also help us approximate other probability distributions, such as binomial distribution, Poisson distribution, etc.\n",
    "\n",
    "[<img src=\"https://www.freecodecamp.org/news/content/images/2020/08/normal_dist_68_rule.jpg\" width=500/>](https://www.freecodecamp.org/news/content/images/2020/08/normal_dist_68_rule.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791920fe-214a-439d-8151-678abf3122e7",
   "metadata": {},
   "source": [
    "## Difference between Data Mining, Statistics, Machine Learning and AI. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7792018c-3171-4735-8dcd-3f44d744dee0",
   "metadata": {},
   "source": [
    "Data mining, statistics, machine learning, and artificial intelligence are four related but distinct fields that have different goals, methods, and applications.\n",
    "\n",
    "- **Data mining** <u>is the process of discovering patterns, trends, and relationships in large and complex data sets</u>. Data mining uses techniques from machine learning, statistics, and other disciplines to extract useful information and knowledge from data. Data mining can be used for various purposes, such as business intelligence, customer segmentation, fraud detection, market analysis, etc.\n",
    "\n",
    "- **Statistics** <u>is the science of collecting, organizing, analyzing, and interpreting data</u>. Statistics uses mathematical models and methods to describe and infer the properties of populations and samples. Statistics can be used for testing hypotheses, estimating parameters, making predictions, etc.\n",
    "\n",
    "- Machine learning is the branch of artificial intelligence that focuses on creating systems that can learn from data and improve their performance. Machine learning uses algorithms that can automatically find patterns, rules, and features in data and use them to make predictions or decisions. Machine learning can be used for various tasks, such as classification, regression, clustering, recommendation, etc.\n",
    "\n",
    "- **Artificial intelligence** is the field of computer science that aims to create systems that can perform tasks that normally require human intelligence. Artificial intelligence encompasses various subfields, such as machine learning, natural language processing, computer vision, robotics, etc. Artificial intelligence can be used for various applications, such as speech recognition, image analysis, game playing, self-driving cars, etc.\n",
    "\n",
    "**Some of the similarities and differences between these fields are:**\n",
    "\n",
    "- Data mining and machine learning are both concerned with finding patterns and knowledge from data, but data mining is more application-oriented and machine learning is more algorithm-oriented.\n",
    "\n",
    "- Statistics and machine learning are both concerned with analyzing data and making inferences from data, but statistics is more theory-based and machine learning is more computation-based.\n",
    "\n",
    "- Machine learning and artificial intelligence are both concerned with creating systems that can perform intelligent tasks, but machine learning is more data-driven and artificial intelligence is more goal-driven.\n",
    "\n",
    "- Data mining and statistics are both concerned with extracting information from data, but data mining is more exploratory and statistics is more confirmatory.\n",
    "\n",
    "**These fields are not mutually exclusive and often overlap with each other.** \n",
    "\n",
    "For example:\n",
    "\n",
    "- Data mining can use techniques from statistics and machine learning to analyze data.\n",
    "\n",
    "- Statistics can use techniques from machine learning and artificial intelligence to model data.\n",
    "\n",
    "- Machine learning can use techniques from statistics and data mining to learn from data.\n",
    "\n",
    "- Artificial intelligence can use techniques from machine learning and data mining to achieve intelligent behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e763986a-d205-4c7d-b3ef-91229f8b1ebd",
   "metadata": {},
   "source": [
    "## Difference between Normalisation and Standardisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba4c17f-9fad-448c-86a8-472003d65cda",
   "metadata": {},
   "source": [
    "Normalization and standardization are two common techniques for scaling data in machine learning. Scaling data means transforming the values of the features to a common range or scale, such as 0 to 1 or -1 to 1. Scaling data can help improve the performance and convergence of some machine learning algorithms, especially those that use distance-based metrics, such as k-nearest neighbors, k-means, and support vector machines.\n",
    "\n",
    "Here are some key insights about the difference between normalization and standardization:\n",
    "\n",
    "- Normalization rescales the values of a feature to the range of 0 to 1. It subtracts the minimum value of the feature from each value, and then divides by the range of the feature. Normalization is also known as min-max scaling. The formula for normalization is:\n",
    "\n",
    "$$x_{new} = \\frac{x - x_{min}}{x_{max} - x_{min}}$$\n",
    "\n",
    "- Standardization rescales the values of a feature to have a mean of 0 and a standard deviation of 1. It subtracts the mean of the feature from each value, and then divides by the standard deviation of the feature. Standardization is also known as z-score normalization. The formula for standardization is:\n",
    "\n",
    "$$x_{new} = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "- Normalization is useful when the features have different scales or units, and we want to bring them to a common scale without distorting the differences in the range of values. For example, if one feature is measured in meters and another is measured in kilometers, we might want to normalize them to compare them on a similar scale.\n",
    "\n",
    "- Standardization is useful when the features have different distributions, and we want to make them more Gaussian-like. This can improve the performance of some machine learning algorithms that assume normality, such as linear regression, logistic regression, and linear discriminant analysis.\n",
    "\n",
    "- Normalization is sensitive to outliers, meaning that if there are extreme values in the data, they will affect the scaling of the rest of the data. Standardization is more robust to outliers, meaning that they have less impact on the scaling of the data.\n",
    "\n",
    "- Normalization bounds the values of the features between 0 and 1, which can be useful for some algorithms that require this range, such as neural networks and gradient descent. Standardization does not bound the values of the features, which can be useful for some algorithms that do not require this range, such as principal component analysis and clustering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f6c67c-b085-4605-afcf-a3cd9807abe6",
   "metadata": {},
   "source": [
    "## Difference Between Bias and Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34750609-fe2e-4b28-b1f6-87acf7a33e58",
   "metadata": {},
   "source": [
    "Bias and error are two terms that are often used in statistics and machine learning to describe the accuracy and precision of a measurement or an estimate. \n",
    "\n",
    "- **Error** is the difference between the true value and the estimated value of that quantity. Error can be caused by various sources, such as random noise, measurement errors, sampling errors, model errors, etc. Error can be either random or systematic. Random error is unpredictable and varies from one estimate to another. Systematic error is predictable and consistent across estimates. Systematic error is also known as bias.\n",
    "\n",
    "- **Bias** is the systematic deviation of the estimated value from the true value. Bias indicates that the estimate is not accurate, meaning that it does not reflect the reality. Bias can be caused by various factors, such as faulty instruments, flawed methods, incorrect assumptions, hidden variables, etc. Bias can be either positive or negative. **Positive bias** means that the estimate is higher than the true value. **Negative bias** means that the estimate is lower than the true value.\n",
    "\n",
    "- **Error and bias** are related but not identical concepts. Error measures the total deviation of the estimate from the true value, while bias measures the average deviation of the estimate from the true value. Error includes both random and systematic components, while bias is only the systematic component. Error can be reduced by increasing the sample size or improving the measurement technique, while bias can only be reduced by identifying and eliminating its sources.\n",
    "\n",
    "- **Error and bias** have different implications for statistical inference and machine learning. Error affects the precision and reliability of the estimate, while bias affects the validity and accuracy of the estimate. Error can be quantified by using standard deviation, confidence intervals, or hypothesis tests, while bias can be assessed by using calibration, validation, or cross-validation techniques. Error can be tolerated to some extent, as long as it is within a reasonable range, while bias should be avoided or minimized as much as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8065c507-c26a-4c25-9c3d-a7dc9a9b16d0",
   "metadata": {},
   "source": [
    "## Difference between Standard Error of the Mean and Standard Deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4150ad-e672-4656-a819-3ad94e04e439",
   "metadata": {},
   "source": [
    "The standard error of the mean (SEM) and the standard deviation (SD) are two statistics that measure different aspects of the variability of a data set. \n",
    "\n",
    "The SEM measures how precisely the sample mean estimates the population mean, while the SD measures how spread out the individual data values are around the sample mean.\n",
    "\n",
    "- The SEM is calculated by dividing the SD by the square root of the sample size, while the SD is calculated by taking the square root of the variance, which is the average of the squared deviations from the mean. The formulas for SEM and SD are:\n",
    "\n",
    "$$\\text{SEM} = \\frac{\\text{SD}}{\\sqrt{n}}$$\n",
    "\n",
    "$$\\text{SD} = \\sqrt{\\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{n-1}}$$\n",
    "\n",
    "where $n$ is the sample size, $x_i$ is the $i$th data value, and $\\bar{x}$ is the sample mean.\n",
    "\n",
    "- The SEM is always smaller than or equal to the SD, because it is obtained by dividing the SD by a positive number. The SEM decreases as the sample size increases, while the SD does not depend on the sample size. The SEM reflects how much variation there is in the sampling distribution of the mean, while the SD reflects how much variation there is in the original data set.\n",
    "\n",
    "- The SEM is used to quantify the uncertainty or margin of error around an estimate of the population mean, while the SD is used to describe the dispersion or variability of a data set. The SEM can be used to construct confidence intervals for the population mean, while the SD can be used to compare different data sets or identify outliers. The SEM indicates how accurate an estimate is, while the SD indicates how precise an estimate is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee4555d-071d-4465-be07-e19720fefe0f",
   "metadata": {},
   "source": [
    "## Difference between Confidence Interval and Confidence Level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f40b172-e426-4b64-8ac1-eeab83a65438",
   "metadata": {},
   "source": [
    "Confidence interval and confidence level are two related concepts in statistics that are often used to measure the uncertainty and precision of an estimate. Here are some key insights about the difference between them:\n",
    "\n",
    "- A **confidence interval** is a <u>range</u> of values that is likely to contain the true value of a population parameter, such as the mean, the proportion, or the difference between two groups. A confidence interval is calculated from a sample statistic, such as the sample mean, the sample proportion, or the sample difference, and an associated margin of error. The margin of error depends on the standard error of the statistic, the sample size, and the chosen confidence level. A confidence interval can be expressed as a point estimate ± margin of error, or as a lower bound and an upper bound. For example, a 95% confidence interval for the mean height of men in a country might be 175.6 ± 2.1 cm, or equivalently, (173.5 cm, 177.7 cm).\n",
    "\n",
    "- A **confidence level** is the <u>probability</u> that a confidence interval will contain the true value of a population parameter. A confidence level is usually expressed as a percentage, such as 90%, 95%, or 99%. A higher confidence level means that the confidence interval is more likely to capture the true value, but it also means that the confidence interval is wider and less precise. A lower confidence level means that the confidence interval is less likely to capture the true value, but it also means that the confidence interval is narrower and more precise. A confidence level can be interpreted as the degree of certainty that a confidence interval will contain the true value of a population parameter. For example, if we have a 95% confidence level, it means that we are 95% confident that the interval we calculated from our sample data covers the true value of the parameter we are interested in. However, this does not mean that the true value is fixed or known, or that it has a 95% probability of being in the interval. It only means that if we repeated the sampling process many times, 95% of the intervals we obtained would include the true value. \n",
    "\n",
    "- A confidence level is a measure of how reliable our estimate is, based on the sample size, the variability of the data, and the chosen confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b71711f-e1c1-42ef-b4d4-46fc20057cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
